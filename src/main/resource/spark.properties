java.io.tmpdir=/hadoop/temp
spark.serialize=org.apache.spark.serializer.KryoSerializer
spark.akka.frameSize=1024
spark.kryoserializer.buffer.mb=512
spark.streaming.unpersist=true
spark.cleaner.ttl=36000
spark.scheduler.mode=FAIR
spark.storage.memoryFraction=0.6
spark.rdd.compress=true
spark.shuffle.compress=true
spark.io.compression.codec=org.apache.spark.io.SnappyCompressionCodec
spark.streaming.blockInterval=20000
spark.shuffle.manager=SORT
spark.scheduler.allocation.file=/data1/pool.xml
spark.streaming.receiver.maxRate=40000
spark.default.parallelism=74
#spark.hadoop.parquet.page.size=1073741824
#spark.hadoop.parquet.dictionary.page.size=268435456
#spark.hadoop.parquet.block.size=1073741824
#spark.buffer.size=1048576
#spark.hadoop.parquet.compression=parquet.hadoop.codec.SnappyCodec
#spark.locality.wait=40000

#spark.storage.blockManagerSlaveTimeoutMs=8000000
#spark.storage.blockManagerHeartBeatMs=8000000
#spark.streaming.receiver.writeAheadLog.enable=true
#spark.ui.port=4050